{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependnecies",
   "id": "ecd20a88e1eaa464"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:26.009641900Z",
     "start_time": "2026-02-26T18:42:25.987976500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ],
   "id": "e5094452cadb637b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading",
   "id": "1ad1ce4276d2d063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:26.039778700Z",
     "start_time": "2026-02-26T18:42:26.012772500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_experiment_data(base_dir):\n",
    "    base_path = Path(base_dir)\n",
    "    data = {}\n",
    "    \n",
    "    # Iterate through prompt templates\n",
    "    for prompt_dir in base_path.iterdir():\n",
    "        if not prompt_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        prompt_name = prompt_dir.name\n",
    "        data[prompt_name] = {}\n",
    "        \n",
    "        # Iterate through datasets\n",
    "        for dataset_dir in prompt_dir.iterdir():\n",
    "            if not dataset_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            dataset_name = dataset_dir.name\n",
    "            data[prompt_name][dataset_name] = {}\n",
    "            \n",
    "            # Iterate through runs\n",
    "            for run_dir in dataset_dir.iterdir():\n",
    "                if not run_dir.is_dir():\n",
    "                    continue\n",
    "                    \n",
    "                run_id = run_dir.name\n",
    "                data[prompt_name][dataset_name][run_id] = {}\n",
    "                \n",
    "                # Load detailed_results.json\n",
    "                detailed_results_path = run_dir / \"detailed_results.json\"\n",
    "                if detailed_results_path.exists():\n",
    "                    with open(detailed_results_path, 'r') as f:\n",
    "                        data[prompt_name][dataset_name][run_id]['detailed_results'] = json.load(f)\n",
    "                \n",
    "                # Load energy.csv\n",
    "                energy_path = run_dir / \"energy.csv\"\n",
    "                if energy_path.exists():\n",
    "                    data[prompt_name][dataset_name][run_id]['energy_df'] = pd.read_csv(energy_path)\n",
    "    \n",
    "    return data"
   ],
   "id": "475b273d5b9f048b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "0haglkg7adrl",
   "source": [
    "# Example usage\n",
    "experiment_data = load_experiment_data(\"..\\\\outputs\\\\run_20260225_115145\\\\bigcode_starcoder2-3b\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:26.846484200Z",
     "start_time": "2026-02-26T18:42:26.051687800Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "674ds44vd8q",
   "source": "def flatten_experiment_data(experiment_data):\n    \"\"\"\n    Flatten nested experiment data into a single DataFrame.\n    \n    Args:\n        experiment_data: Nested dictionary from load_experiment_data()\n    \n    Returns:\n        DataFrame where:\n        - Each row represents one run (prompt_template/dataset/run_id combination)\n        - Columns include metadata (prompt, dataset, run_id) \n        - Energy columns contain arrays (one per CSV column)\n        - Detailed results columns contain flattened lists extracted from all tasks\n    \"\"\"\n    rows = []\n    \n    for prompt_name, prompt_data in experiment_data.items():\n        for dataset_name, dataset_data in prompt_data.items():\n            for run_id, run_data in dataset_data.items():\n                row = {\n                    'prompt_template': prompt_name,\n                    'dataset': dataset_name,\n                    'run_id': run_id\n                }\n                \n                # Process energy data - store each column as an array\n                if 'energy_df' in run_data:\n                    energy_df = run_data['energy_df']\n                    for col in energy_df.columns:\n                        row[f'energy_{col}'] = energy_df[col].values\n                \n                # Process detailed results - flatten list of dicts\n                if 'detailed_results' in run_data:\n                    detailed_results = run_data['detailed_results']\n                    \n                    if len(detailed_results) > 0:\n                        # Get all keys from the first task (assuming uniform structure)\n                        sample_task = detailed_results[0]\n                        \n                        # For each key in the task dict, collect values across all tasks\n                        for key in sample_task.keys():\n                            # Handle nested metrics dict separately\n                            if key == 'metrics' and isinstance(sample_task[key], dict):\n                                # Flatten metrics sub-keys\n                                for metric_key in sample_task[key].keys():\n                                    row[f'results_metrics_{metric_key}'] = [\n                                        task['metrics'].get(metric_key) \n                                        for task in detailed_results\n                                    ]\n                            else:\n                                # Regular key - collect all values as list\n                                row[f'results_{key}'] = [\n                                    task.get(key) \n                                    for task in detailed_results\n                                ]\n                \n                # Add summary if exists\n                if 'summary' in run_data:\n                    for key, value in run_data['summary'].items():\n                        row[f'summary_{key}'] = value\n                \n                rows.append(row)\n    \n    return pd.DataFrame(rows)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:27.338803Z",
     "start_time": "2026-02-26T18:42:27.323009500Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "978f5sbtzsm",
   "source": [
    "# Create flattened DataFrame\n",
    "df = flatten_experiment_data(experiment_data)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:27.476868100Z",
     "start_time": "2026-02-26T18:42:27.338803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (12, 96)\n",
      "\n",
      "Columns: ['prompt_template', 'dataset', 'run_id', 'energy_Delta', 'energy_Time', 'energy_CORE0_ENERGY (J)', 'energy_CORE0_FREQ (MHZ)', 'energy_CORE0_PSTATE', 'energy_CORE0_VOLT (V)', 'energy_CPU_ENERGY (J)', 'energy_CPU_FREQUENCY_0', 'energy_CPU_FREQUENCY_1', 'energy_CPU_FREQUENCY_10', 'energy_CPU_FREQUENCY_11', 'energy_CPU_FREQUENCY_12', 'energy_CPU_FREQUENCY_13', 'energy_CPU_FREQUENCY_14', 'energy_CPU_FREQUENCY_15', 'energy_CPU_FREQUENCY_16', 'energy_CPU_FREQUENCY_17', 'energy_CPU_FREQUENCY_18', 'energy_CPU_FREQUENCY_19', 'energy_CPU_FREQUENCY_2', 'energy_CPU_FREQUENCY_20', 'energy_CPU_FREQUENCY_21', 'energy_CPU_FREQUENCY_22', 'energy_CPU_FREQUENCY_23', 'energy_CPU_FREQUENCY_24', 'energy_CPU_FREQUENCY_25', 'energy_CPU_FREQUENCY_26', 'energy_CPU_FREQUENCY_27', 'energy_CPU_FREQUENCY_28', 'energy_CPU_FREQUENCY_29', 'energy_CPU_FREQUENCY_3', 'energy_CPU_FREQUENCY_30', 'energy_CPU_FREQUENCY_31', 'energy_CPU_FREQUENCY_4', 'energy_CPU_FREQUENCY_5', 'energy_CPU_FREQUENCY_6', 'energy_CPU_FREQUENCY_7', 'energy_CPU_FREQUENCY_8', 'energy_CPU_FREQUENCY_9', 'energy_CPU_USAGE_0', 'energy_CPU_USAGE_1', 'energy_CPU_USAGE_10', 'energy_CPU_USAGE_11', 'energy_CPU_USAGE_12', 'energy_CPU_USAGE_13', 'energy_CPU_USAGE_14', 'energy_CPU_USAGE_15', 'energy_CPU_USAGE_16', 'energy_CPU_USAGE_17', 'energy_CPU_USAGE_18', 'energy_CPU_USAGE_19', 'energy_CPU_USAGE_2', 'energy_CPU_USAGE_20', 'energy_CPU_USAGE_21', 'energy_CPU_USAGE_22', 'energy_CPU_USAGE_23', 'energy_CPU_USAGE_24', 'energy_CPU_USAGE_25', 'energy_CPU_USAGE_26', 'energy_CPU_USAGE_27', 'energy_CPU_USAGE_28', 'energy_CPU_USAGE_29', 'energy_CPU_USAGE_3', 'energy_CPU_USAGE_30', 'energy_CPU_USAGE_31', 'energy_CPU_USAGE_4', 'energy_CPU_USAGE_5', 'energy_CPU_USAGE_6', 'energy_CPU_USAGE_7', 'energy_CPU_USAGE_8', 'energy_CPU_USAGE_9', 'energy_GPU0_MEMORY_TOTAL', 'energy_GPU0_MEMORY_USED', 'energy_GPU0_POWER (mWatts)', 'energy_GPU0_TEMPERATURE', 'energy_GPU0_USAGE', 'energy_TOTAL_MEMORY', 'energy_TOTAL_SWAP', 'energy_USED_MEMORY', 'energy_USED_SWAP', 'results_task_id', 'results_prompt', 'results_raw_response', 'results_extracted_code', 'results_reference', 'results_metrics_edit_distance', 'results_metrics_edit_distance_normalized', 'results_metrics_levenshtein_ratio', 'results_metrics_rouge_l_precision', 'results_metrics_rouge_l_recall', 'results_metrics_rouge_l_fmeasure', 'results_metrics_codebleu', 'results_metrics_codebleu_ngram_match']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         prompt_template           dataset run_id  \\\n",
       "0    answer_only_no_expl  humaneval_custom     r1   \n",
       "1    answer_only_no_expl  humaneval_custom     r2   \n",
       "2    answer_only_no_expl  humaneval_custom     r3   \n",
       "3   baseline_single_shot  humaneval_custom     r1   \n",
       "4   baseline_single_shot  humaneval_custom     r2   \n",
       "5   baseline_single_shot  humaneval_custom     r3   \n",
       "6     polite_single_shot  humaneval_custom     r1   \n",
       "7     polite_single_shot  humaneval_custom     r2   \n",
       "8     polite_single_shot  humaneval_custom     r3   \n",
       "9     think_step_by_step  humaneval_custom     r1   \n",
       "10    think_step_by_step  humaneval_custom     r2   \n",
       "11    think_step_by_step  humaneval_custom     r3   \n",
       "\n",
       "                                         energy_Delta  \\\n",
       "0   [0, 200, 199, 200, 200, 199, 200, 200, 200, 20...   \n",
       "1   [0, 200, 200, 199, 199, 199, 199, 200, 199, 19...   \n",
       "2   [0, 200, 200, 200, 199, 199, 199, 199, 199, 20...   \n",
       "3   [0, 199, 199, 200, 200, 200, 199, 200, 200, 20...   \n",
       "4   [0, 199, 199, 199, 199, 199, 199, 199, 200, 20...   \n",
       "5   [0, 200, 199, 199, 199, 199, 200, 199, 200, 19...   \n",
       "6   [0, 200, 199, 199, 200, 199, 199, 200, 199, 19...   \n",
       "7   [0, 200, 199, 199, 199, 200, 200, 200, 200, 19...   \n",
       "8   [0, 200, 200, 200, 200, 199, 200, 199, 199, 19...   \n",
       "9   [0, 200, 200, 199, 199, 200, 200, 200, 200, 19...   \n",
       "10  [0, 200, 199, 199, 200, 200, 199, 200, 199, 19...   \n",
       "11  [0, 200, 199, 199, 200, 200, 200, 200, 200, 20...   \n",
       "\n",
       "                                          energy_Time  \\\n",
       "0   [1772027861046, 1772027861046, 1772027861247, ...   \n",
       "1   [1772047370021, 1772047370021, 1772047370221, ...   \n",
       "2   [1772033426056, 1772033426056, 1772033426257, ...   \n",
       "3   [1772041774021, 1772041774021, 1772041774221, ...   \n",
       "4   [1772044568861, 1772044568861, 1772044569061, ...   \n",
       "5   [1772022307384, 1772022307384, 1772022307584, ...   \n",
       "6   [1772036208783, 1772036208783, 1772036208984, ...   \n",
       "7   [1772038990750, 1772038990750, 1772038990950, ...   \n",
       "8   [1772019512917, 1772019512917, 1772019513117, ...   \n",
       "9   [1772030641944, 1772030641944, 1772030642144, ...   \n",
       "10  [1772016708134, 1772016708134, 1772016708335, ...   \n",
       "11  [1772025085137, 1772025085137, 1772025085338, ...   \n",
       "\n",
       "                              energy_CORE0_ENERGY (J)  \\\n",
       "0   [106485.80258178712, 77665.18424987793, 106487...   \n",
       "1   [238117.0500640869, 238117.12771606445, 155487...   \n",
       "2   [145054.76817321777, 98108.92973327637, 98109....   \n",
       "3   [203535.9206085205, 129099.17764282228, 203537...   \n",
       "4   [220602.5231781006, 142705.16804504397, 142706...   \n",
       "5   [67694.29295349121, 57039.04733276367, 30479.8...   \n",
       "6   [164472.97360229492, 164473.11978149414, 16447...   \n",
       "7   [184011.3512878418, 184011.527633667, 184012.3...   \n",
       "8   [51634.569915771484, 48148.05140686035, 51635....   \n",
       "9   [125805.66015625, 87635.07162475586, 125806.69...   \n",
       "10  [17930.760284423828, 36379.41401672363, 37632....   \n",
       "11  [67234.56271362305, 67234.63124084473, 87351.6...   \n",
       "\n",
       "                              energy_CORE0_FREQ (MHZ)  \\\n",
       "0   [5450.0, 5450.0, 5125.0, 2311.111111111111, 52...   \n",
       "1   [5450.0, 5450.0, 5375.0, 5150.0, 5225.0, 5250....   \n",
       "2   [5450.0, 5400.0, 5100.0, 5250.0, 5225.0, 5225....   \n",
       "3   [5450.0, 5450.0, 5375.0, 5100.0, 5300.0, 5225....   \n",
       "4   [5450.0, 5450.0, 5275.0, 5175.0, 5400.0, 5100....   \n",
       "5   [5450.0, 5325.0, 5125.0, 2300.0, 5225.0, 5250....   \n",
       "6   [5450.0, 5375.0, 5375.0, 5250.0, 5300.0, 5250....   \n",
       "7   [5450.0, 5425.0, 5175.0, 5225.0, 5150.0, 5225....   \n",
       "8   [5400.0, 5275.0, 5325.0, 5000.0, 5375.0, 5375....   \n",
       "9   [5450.0, 5350.0, 5100.0, 5200.0, 5225.0, 5175....   \n",
       "10  [2422.222222222222, 5450.0, 5175.0, 5175.0, 52...   \n",
       "11  [5450.0, 5400.0, 5125.0, 5150.0, 5325.0, 5200....   \n",
       "\n",
       "                                  energy_CORE0_PSTATE  \\\n",
       "0   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "5   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                energy_CORE0_VOLT (V)  \\\n",
       "0   [0.3125, 0.1812499999999999, 0.368749999999999...   \n",
       "1   [0.1937499999999998, 0.1937499999999998, 0.274...   \n",
       "2   [0.1875, 0.2375, 0.3562499999999999, 0.33125, ...   \n",
       "3   [0.1812499999999999, 0.1875, 0.243749999999999...   \n",
       "4   [0.1875, 0.1999999999999999, 0.287499999999999...   \n",
       "5   [0.20625, 0.3062499999999999, 0.38125000000000...   \n",
       "6   [0.1999999999999999, 0.25, 0.2562499999999998,...   \n",
       "7   [0.15625, 0.2249999999999998, 0.33749999999999...   \n",
       "8   [0.25, 0.2874999999999998, 0.28125, 0.41250000...   \n",
       "9   [0.1875, 0.2249999999999998, 0.39375, 0.349999...   \n",
       "10  [0.20625, 0.1875, 0.3687499999999999, 0.356249...   \n",
       "11  [0.2249999999999998, 0.1937499999999998, 0.393...   \n",
       "\n",
       "                                energy_CPU_ENERGY (J)  ...  \\\n",
       "0   [752708.6723480225, 752709.2333526611, 752717....  ...   \n",
       "1   [1421564.264312744, 1421565.0434570312, 142157...  ...   \n",
       "2   [943715.4232940674, 943716.6347045898, 943724....  ...   \n",
       "3   [1230367.723373413, 1230368.5049743652, 123037...  ...   \n",
       "4   [1325904.9857177734, 1325905.8044586182, 13259...  ...   \n",
       "5   [563109.3822784424, 563110.0404815674, 563118....  ...   \n",
       "6   [1039424.2096405028, 1039425.7497558594, 10394...  ...   \n",
       "7   [1135230.1230773926, 1135231.378158569, 113523...  ...   \n",
       "8   [471062.4437713623, 471063.86393737793, 471071...  ...   \n",
       "9   [848597.1455535889, 848597.7242889404, 848605....  ...   \n",
       "10  [373769.5879821777, 373770.15409851074, 373778...  ...   \n",
       "11  [658319.513595581, 658320.0283203125, 658327.9...  ...   \n",
       "\n",
       "                               results_extracted_code  \\\n",
       "0   [, , , def hello_world():\\n    \"\"\"\\n    >>> he...   \n",
       "1   [, , , def hello_world():\\n    \"\"\"\\n    >>> he...   \n",
       "2   [, , , def hello_world():\\n    \"\"\"\\n    >>> he...   \n",
       "3   [def has_close_elements(numbers: List[float], ...   \n",
       "4   [def has_close_elements(numbers: List[float], ...   \n",
       "5   [def has_close_elements(numbers: List[float], ...   \n",
       "6   [, , , def below_zero(operations: List[int]) -...   \n",
       "7   [, , , def below_zero(operations: List[int]) -...   \n",
       "8   [, , , def below_zero(operations: List[int]) -...   \n",
       "9   [, , , def below_zero(operations: List[int]) -...   \n",
       "10  [, , , def below_zero(operations: List[int]) -...   \n",
       "11  [, , , def below_zero(operations: List[int]) -...   \n",
       "\n",
       "                                    results_reference  \\\n",
       "0   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "1   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "2   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "3   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "4   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "5   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "6   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "7   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "8   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "9   [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "10  [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "11  [    for idx, elem in enumerate(numbers):\\n   ...   \n",
       "\n",
       "                        results_metrics_edit_distance  \\\n",
       "0   [252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...   \n",
       "1   [252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...   \n",
       "2   [252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...   \n",
       "3   [345, 396, 299, 768, 350, 273, 649, 308, 265, ...   \n",
       "4   [345, 396, 299, 768, 350, 273, 649, 308, 265, ...   \n",
       "5   [345, 396, 299, 768, 350, 273, 649, 308, 265, ...   \n",
       "6   [252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...   \n",
       "7   [252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...   \n",
       "8   [252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...   \n",
       "9   [252, 419, 24, 439, 384, 192, 300, 1511, 162, ...   \n",
       "10  [252, 419, 24, 439, 384, 192, 300, 1511, 162, ...   \n",
       "11  [252, 419, 24, 439, 384, 192, 300, 1511, 162, ...   \n",
       "\n",
       "             results_metrics_edit_distance_normalized  \\\n",
       "0   [1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...   \n",
       "1   [1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...   \n",
       "2   [1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...   \n",
       "3   [0.6872509960159362, 0.7557251908396947, 0.934...   \n",
       "4   [0.6872509960159362, 0.7557251908396947, 0.934...   \n",
       "5   [0.6872509960159362, 0.7557251908396947, 0.934...   \n",
       "6   [1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...   \n",
       "7   [1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...   \n",
       "8   [1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...   \n",
       "9   [1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...   \n",
       "10  [1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...   \n",
       "11  [1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...   \n",
       "\n",
       "                    results_metrics_levenshtein_ratio  \\\n",
       "0   [0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...   \n",
       "1   [0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...   \n",
       "2   [0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...   \n",
       "3   [0.46153846153846156, 0.37751855779427357, 0.1...   \n",
       "4   [0.46153846153846156, 0.37751855779427357, 0.1...   \n",
       "5   [0.46153846153846156, 0.37751855779427357, 0.1...   \n",
       "6   [0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...   \n",
       "7   [0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...   \n",
       "8   [0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...   \n",
       "9   [0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...   \n",
       "10  [0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...   \n",
       "11  [0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...   \n",
       "\n",
       "                    results_metrics_rouge_l_precision  \\\n",
       "0   [0, 0, 0, 0.038461538461538464, 0.117647058823...   \n",
       "1   [0, 0, 0, 0.038461538461538464, 0.117647058823...   \n",
       "2   [0, 0, 0, 0.038461538461538464, 0.117647058823...   \n",
       "3   [0.1566265060240964, 0.057971014492753624, 0.0...   \n",
       "4   [0.1566265060240964, 0.057971014492753624, 0.0...   \n",
       "5   [0.1566265060240964, 0.057971014492753624, 0.0...   \n",
       "6   [0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...   \n",
       "7   [0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...   \n",
       "8   [0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...   \n",
       "9   [0, 0, 0, 0.1566265060240964, 0.08955223880597...   \n",
       "10  [0, 0, 0, 0.1566265060240964, 0.08955223880597...   \n",
       "11  [0, 0, 0, 0.1566265060240964, 0.08955223880597...   \n",
       "\n",
       "                       results_metrics_rouge_l_recall  \\\n",
       "0   [0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...   \n",
       "1   [0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...   \n",
       "2   [0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...   \n",
       "3   [0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...   \n",
       "4   [0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...   \n",
       "5   [0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...   \n",
       "6   [0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...   \n",
       "7   [0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...   \n",
       "8   [0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...   \n",
       "9   [0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...   \n",
       "10  [0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...   \n",
       "11  [0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...   \n",
       "\n",
       "                     results_metrics_rouge_l_fmeasure  \\\n",
       "0   [0, 0, 0, 0.04878048780487805, 0.1212121212121...   \n",
       "1   [0, 0, 0, 0.04878048780487805, 0.1212121212121...   \n",
       "2   [0, 0, 0, 0.04878048780487805, 0.1212121212121...   \n",
       "3   [0.23853211009174313, 0.07142857142857142, 0.0...   \n",
       "4   [0.23853211009174313, 0.07142857142857142, 0.0...   \n",
       "5   [0.23853211009174313, 0.07142857142857142, 0.0...   \n",
       "6   [0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...   \n",
       "7   [0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...   \n",
       "8   [0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...   \n",
       "9   [0, 0, 0, 0.2653061224489796, 0.14457831325301...   \n",
       "10  [0, 0, 0, 0.2653061224489796, 0.14457831325301...   \n",
       "11  [0, 0, 0, 0.2653061224489796, 0.14457831325301...   \n",
       "\n",
       "                             results_metrics_codebleu  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3   [0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...   \n",
       "4   [0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...   \n",
       "5   [0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...   \n",
       "6   [0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...   \n",
       "7   [0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...   \n",
       "8   [0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...   \n",
       "9   [0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...   \n",
       "10  [0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...   \n",
       "11  [0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...   \n",
       "\n",
       "                 results_metrics_codebleu_ngram_match  \n",
       "0   [0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...  \n",
       "1   [0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...  \n",
       "2   [0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...  \n",
       "3   [0.20634920634920634, 0.02631578947368421, 0.0...  \n",
       "4   [0.20634920634920634, 0.02631578947368421, 0.0...  \n",
       "5   [0.20634920634920634, 0.02631578947368421, 0.0...  \n",
       "6   [0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...  \n",
       "7   [0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...  \n",
       "8   [0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...  \n",
       "9   [0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...  \n",
       "10  [0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...  \n",
       "11  [0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...  \n",
       "\n",
       "[12 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>dataset</th>\n",
       "      <th>run_id</th>\n",
       "      <th>energy_Delta</th>\n",
       "      <th>energy_Time</th>\n",
       "      <th>energy_CORE0_ENERGY (J)</th>\n",
       "      <th>energy_CORE0_FREQ (MHZ)</th>\n",
       "      <th>energy_CORE0_PSTATE</th>\n",
       "      <th>energy_CORE0_VOLT (V)</th>\n",
       "      <th>energy_CPU_ENERGY (J)</th>\n",
       "      <th>...</th>\n",
       "      <th>results_extracted_code</th>\n",
       "      <th>results_reference</th>\n",
       "      <th>results_metrics_edit_distance</th>\n",
       "      <th>results_metrics_edit_distance_normalized</th>\n",
       "      <th>results_metrics_levenshtein_ratio</th>\n",
       "      <th>results_metrics_rouge_l_precision</th>\n",
       "      <th>results_metrics_rouge_l_recall</th>\n",
       "      <th>results_metrics_rouge_l_fmeasure</th>\n",
       "      <th>results_metrics_codebleu</th>\n",
       "      <th>results_metrics_codebleu_ngram_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answer_only_no_expl</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r1</td>\n",
       "      <td>[0, 200, 199, 200, 200, 199, 200, 200, 200, 20...</td>\n",
       "      <td>[1772027861046, 1772027861046, 1772027861247, ...</td>\n",
       "      <td>[106485.80258178712, 77665.18424987793, 106487...</td>\n",
       "      <td>[5450.0, 5450.0, 5125.0, 2311.111111111111, 52...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.3125, 0.1812499999999999, 0.368749999999999...</td>\n",
       "      <td>[752708.6723480225, 752709.2333526611, 752717....</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def hello_world():\\n    \"\"\"\\n    &gt;&gt;&gt; he...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...</td>\n",
       "      <td>[0, 0, 0, 0.038461538461538464, 0.117647058823...</td>\n",
       "      <td>[0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...</td>\n",
       "      <td>[0, 0, 0, 0.04878048780487805, 0.1212121212121...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_only_no_expl</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r2</td>\n",
       "      <td>[0, 200, 200, 199, 199, 199, 199, 200, 199, 19...</td>\n",
       "      <td>[1772047370021, 1772047370021, 1772047370221, ...</td>\n",
       "      <td>[238117.0500640869, 238117.12771606445, 155487...</td>\n",
       "      <td>[5450.0, 5450.0, 5375.0, 5150.0, 5225.0, 5250....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.1937499999999998, 0.1937499999999998, 0.274...</td>\n",
       "      <td>[1421564.264312744, 1421565.0434570312, 142157...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def hello_world():\\n    \"\"\"\\n    &gt;&gt;&gt; he...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...</td>\n",
       "      <td>[0, 0, 0, 0.038461538461538464, 0.117647058823...</td>\n",
       "      <td>[0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...</td>\n",
       "      <td>[0, 0, 0, 0.04878048780487805, 0.1212121212121...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answer_only_no_expl</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r3</td>\n",
       "      <td>[0, 200, 200, 200, 199, 199, 199, 199, 199, 20...</td>\n",
       "      <td>[1772033426056, 1772033426056, 1772033426257, ...</td>\n",
       "      <td>[145054.76817321777, 98108.92973327637, 98109....</td>\n",
       "      <td>[5450.0, 5400.0, 5100.0, 5250.0, 5225.0, 5225....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0.1875, 0.2375, 0.3562499999999999, 0.33125, ...</td>\n",
       "      <td>[943715.4232940674, 943716.6347045898, 943724....</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def hello_world():\\n    \"\"\"\\n    &gt;&gt;&gt; he...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 168, 98, 192, 1147, 185, 124, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7887323943661971, 0.84482758...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.31976744186046513, 0.3041474...</td>\n",
       "      <td>[0, 0, 0, 0.038461538461538464, 0.117647058823...</td>\n",
       "      <td>[0, 0, 0, 0.06666666666666667, 0.125, 0, 0.116...</td>\n",
       "      <td>[0, 0, 0, 0.04878048780487805, 0.1212121212121...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r1</td>\n",
       "      <td>[0, 199, 199, 200, 200, 200, 199, 200, 200, 20...</td>\n",
       "      <td>[1772041774021, 1772041774021, 1772041774221, ...</td>\n",
       "      <td>[203535.9206085205, 129099.17764282228, 203537...</td>\n",
       "      <td>[5450.0, 5450.0, 5375.0, 5100.0, 5300.0, 5225....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0.1812499999999999, 0.1875, 0.243749999999999...</td>\n",
       "      <td>[1230367.723373413, 1230368.5049743652, 123037...</td>\n",
       "      <td>...</td>\n",
       "      <td>[def has_close_elements(numbers: List[float], ...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[345, 396, 299, 768, 350, 273, 649, 308, 265, ...</td>\n",
       "      <td>[0.6872509960159362, 0.7557251908396947, 0.934...</td>\n",
       "      <td>[0.46153846153846156, 0.37751855779427357, 0.1...</td>\n",
       "      <td>[0.1566265060240964, 0.057971014492753624, 0.0...</td>\n",
       "      <td>[0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...</td>\n",
       "      <td>[0.23853211009174313, 0.07142857142857142, 0.0...</td>\n",
       "      <td>[0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...</td>\n",
       "      <td>[0.20634920634920634, 0.02631578947368421, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r2</td>\n",
       "      <td>[0, 199, 199, 199, 199, 199, 199, 199, 200, 20...</td>\n",
       "      <td>[1772044568861, 1772044568861, 1772044569061, ...</td>\n",
       "      <td>[220602.5231781006, 142705.16804504397, 142706...</td>\n",
       "      <td>[5450.0, 5450.0, 5275.0, 5175.0, 5400.0, 5100....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0.1875, 0.1999999999999999, 0.287499999999999...</td>\n",
       "      <td>[1325904.9857177734, 1325905.8044586182, 13259...</td>\n",
       "      <td>...</td>\n",
       "      <td>[def has_close_elements(numbers: List[float], ...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[345, 396, 299, 768, 350, 273, 649, 308, 265, ...</td>\n",
       "      <td>[0.6872509960159362, 0.7557251908396947, 0.934...</td>\n",
       "      <td>[0.46153846153846156, 0.37751855779427357, 0.1...</td>\n",
       "      <td>[0.1566265060240964, 0.057971014492753624, 0.0...</td>\n",
       "      <td>[0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...</td>\n",
       "      <td>[0.23853211009174313, 0.07142857142857142, 0.0...</td>\n",
       "      <td>[0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...</td>\n",
       "      <td>[0.20634920634920634, 0.02631578947368421, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r3</td>\n",
       "      <td>[0, 200, 199, 199, 199, 199, 200, 199, 200, 19...</td>\n",
       "      <td>[1772022307384, 1772022307384, 1772022307584, ...</td>\n",
       "      <td>[67694.29295349121, 57039.04733276367, 30479.8...</td>\n",
       "      <td>[5450.0, 5325.0, 5125.0, 2300.0, 5225.0, 5250....</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.20625, 0.3062499999999999, 0.38125000000000...</td>\n",
       "      <td>[563109.3822784424, 563110.0404815674, 563118....</td>\n",
       "      <td>...</td>\n",
       "      <td>[def has_close_elements(numbers: List[float], ...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[345, 396, 299, 768, 350, 273, 649, 308, 265, ...</td>\n",
       "      <td>[0.6872509960159362, 0.7557251908396947, 0.934...</td>\n",
       "      <td>[0.46153846153846156, 0.37751855779427357, 0.1...</td>\n",
       "      <td>[0.1566265060240964, 0.057971014492753624, 0.0...</td>\n",
       "      <td>[0.5, 0.09302325581395349, 0.5, 0.4, 0.25, 0.3...</td>\n",
       "      <td>[0.23853211009174313, 0.07142857142857142, 0.0...</td>\n",
       "      <td>[0.08594494135673132, 0.0, 0.0, 0.0, 0.0, 0.07...</td>\n",
       "      <td>[0.20634920634920634, 0.02631578947368421, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>polite_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r1</td>\n",
       "      <td>[0, 200, 199, 199, 200, 199, 199, 200, 199, 19...</td>\n",
       "      <td>[1772036208783, 1772036208783, 1772036208984, ...</td>\n",
       "      <td>[164472.97360229492, 164473.11978149414, 16447...</td>\n",
       "      <td>[5450.0, 5375.0, 5375.0, 5250.0, 5300.0, 5250....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.1999999999999999, 0.25, 0.2562499999999998,...</td>\n",
       "      <td>[1039424.2096405028, 1039425.7497558594, 10394...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...</td>\n",
       "      <td>[0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...</td>\n",
       "      <td>[0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polite_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r2</td>\n",
       "      <td>[0, 200, 199, 199, 199, 200, 200, 200, 200, 19...</td>\n",
       "      <td>[1772038990750, 1772038990750, 1772038990950, ...</td>\n",
       "      <td>[184011.3512878418, 184011.527633667, 184012.3...</td>\n",
       "      <td>[5450.0, 5425.0, 5175.0, 5225.0, 5150.0, 5225....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.15625, 0.2249999999999998, 0.33749999999999...</td>\n",
       "      <td>[1135230.1230773926, 1135231.378158569, 113523...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...</td>\n",
       "      <td>[0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...</td>\n",
       "      <td>[0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>polite_single_shot</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r3</td>\n",
       "      <td>[0, 200, 200, 200, 200, 199, 200, 199, 199, 19...</td>\n",
       "      <td>[1772019512917, 1772019512917, 1772019513117, ...</td>\n",
       "      <td>[51634.569915771484, 48148.05140686035, 51635....</td>\n",
       "      <td>[5400.0, 5275.0, 5325.0, 5000.0, 5375.0, 5375....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.25, 0.2874999999999998, 0.28125, 0.41250000...</td>\n",
       "      <td>[471062.4437713623, 471063.86393737793, 471071...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 1118, 101, 192, 853, 50, 140, 2...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.8972712680577849, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.18736383442265792, 0.0, 0.0,...</td>\n",
       "      <td>[0, 0, 0, 0.06310679611650485, 0, 0, 0.0873786...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0, 0, 0.20930232...</td>\n",
       "      <td>[0, 0, 0, 0.11764705882352941, 0, 0, 0.1232876...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.051211670999810194, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>think_step_by_step</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r1</td>\n",
       "      <td>[0, 200, 200, 199, 199, 200, 200, 200, 200, 19...</td>\n",
       "      <td>[1772030641944, 1772030641944, 1772030642144, ...</td>\n",
       "      <td>[125805.66015625, 87635.07162475586, 125806.69...</td>\n",
       "      <td>[5450.0, 5350.0, 5100.0, 5200.0, 5225.0, 5175....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.1875, 0.2249999999999998, 0.39375, 0.349999...</td>\n",
       "      <td>[848597.1455535889, 848597.7242889404, 848605....</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 439, 384, 192, 300, 1511, 162, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...</td>\n",
       "      <td>[0, 0, 0, 0.1566265060240964, 0.08955223880597...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...</td>\n",
       "      <td>[0, 0, 0, 0.2653061224489796, 0.14457831325301...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>think_step_by_step</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r2</td>\n",
       "      <td>[0, 200, 199, 199, 200, 200, 199, 200, 199, 19...</td>\n",
       "      <td>[1772016708134, 1772016708134, 1772016708335, ...</td>\n",
       "      <td>[17930.760284423828, 36379.41401672363, 37632....</td>\n",
       "      <td>[2422.222222222222, 5450.0, 5175.0, 5175.0, 52...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.20625, 0.1875, 0.3687499999999999, 0.356249...</td>\n",
       "      <td>[373769.5879821777, 373770.15409851074, 373778...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 439, 384, 192, 300, 1511, 162, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...</td>\n",
       "      <td>[0, 0, 0, 0.1566265060240964, 0.08955223880597...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...</td>\n",
       "      <td>[0, 0, 0, 0.2653061224489796, 0.14457831325301...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>think_step_by_step</td>\n",
       "      <td>humaneval_custom</td>\n",
       "      <td>r3</td>\n",
       "      <td>[0, 200, 199, 199, 200, 200, 200, 200, 200, 20...</td>\n",
       "      <td>[1772025085137, 1772025085137, 1772025085338, ...</td>\n",
       "      <td>[67234.56271362305, 67234.63124084473, 87351.6...</td>\n",
       "      <td>[5450.0, 5400.0, 5125.0, 5150.0, 5325.0, 5200....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.2249999999999998, 0.1937499999999998, 0.393...</td>\n",
       "      <td>[658319.513595581, 658320.0283203125, 658327.9...</td>\n",
       "      <td>...</td>\n",
       "      <td>[, , , def below_zero(operations: List[int]) -...</td>\n",
       "      <td>[    for idx, elem in enumerate(numbers):\\n   ...</td>\n",
       "      <td>[252, 419, 24, 439, 384, 192, 300, 1511, 162, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.7783687943262412, 0.83842794...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.36834532374100715, 0.2683363...</td>\n",
       "      <td>[0, 0, 0, 0.1566265060240964, 0.08955223880597...</td>\n",
       "      <td>[0, 0, 0, 0.8666666666666667, 0.375, 0, 0.0, 0...</td>\n",
       "      <td>[0, 0, 0, 0.2653061224489796, 0.14457831325301...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.13479494507318684, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1927710843373494, 0.1, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 96 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "xaazgt4gi0e",
   "source": "def find_sustained_gpu_usage_start(gpu_usage_array, threshold=75, min_consecutive=20):\n    \"\"\"\n    Find the first index where GPU usage is sustained above threshold for min_consecutive measurements.\n    \n    Args:\n        gpu_usage_array: Array of GPU usage values\n        threshold: GPU usage threshold percentage (default: 75)\n        min_consecutive: Minimum number of consecutive measurements above threshold (default: 20)\n    \n    Returns:\n        Index where sustained usage begins, or None if not found\n    \"\"\"\n    if len(gpu_usage_array) < min_consecutive:\n        return None\n    \n    consecutive_count = 0\n    start_idx = None\n    \n    for i, usage in enumerate(gpu_usage_array):\n        if usage > threshold:\n            if consecutive_count == 0:\n                start_idx = i\n            consecutive_count += 1\n            \n            if consecutive_count >= min_consecutive:\n                return start_idx\n        else:\n            consecutive_count = 0\n            start_idx = None\n    \n    return None\n\n\ndef truncate_energy_measurements(df, threshold=75, min_consecutive=20, truncate_end=True):\n    \"\"\"\n    Truncate energy measurements for all runs at start and optionally at end based on GPU usage.\n    \n    Args:\n        df: DataFrame from flatten_experiment_data()\n        threshold: GPU usage threshold percentage (default: 75)\n        min_consecutive: Minimum number of consecutive measurements above/below threshold (default: 20)\n        truncate_end: Whether to also truncate at the end when GPU usage drops (default: True)\n    \n    Returns:\n        Tuple of (truncated_df, truncation_log)\n        - truncated_df: DataFrame with truncated energy arrays\n        - truncation_log: DataFrame with truncation statistics per run\n    \"\"\"\n    df_truncated = df.copy()\n    truncation_log = []\n    \n    # Get all energy column names\n    energy_cols = [col for col in df.columns if col.startswith('energy_')]\n    \n    for idx, row in df_truncated.iterrows():\n        if 'energy_GPU0_USAGE' not in row or row['energy_GPU0_USAGE'] is None:\n            truncation_log.append({\n                'prompt_template': row['prompt_template'],\n                'dataset': row['dataset'],\n                'run_id': row['run_id'],\n                'truncated_start_count': 0,\n                'truncated_end_count': 0,\n                'truncated_total_count': 0,\n                'original_length': 0,\n                'remaining_length': 0,\n                'start_truncation_index': None,\n                'end_truncation_index': None,\n                'status': 'No GPU usage data'\n            })\n            continue\n        \n        gpu_usage = row['energy_GPU0_USAGE']\n        original_length = len(gpu_usage)\n        \n        # Find start truncation point\n        start_idx = find_sustained_gpu_usage_start(gpu_usage, threshold, min_consecutive)\n        \n        # Find end truncation point by reversing the array\n        end_idx = None\n        if truncate_end:\n            reversed_start = find_sustained_gpu_usage_start(gpu_usage[::-1], threshold, min_consecutive)\n            if reversed_start is not None:\n                # Convert reversed index back to original array index\n                end_idx = original_length - reversed_start\n        \n        if start_idx is None and end_idx is None:\n            truncation_log.append({\n                'prompt_template': row['prompt_template'],\n                'dataset': row['dataset'],\n                'run_id': row['run_id'],\n                'truncated_start_count': 0,\n                'truncated_end_count': 0,\n                'truncated_total_count': 0,\n                'original_length': original_length,\n                'remaining_length': original_length,\n                'start_truncation_index': None,\n                'end_truncation_index': None,\n                'status': 'No sustained GPU usage found'\n            })\n            continue\n        \n        # Apply truncation\n        truncated_start = start_idx if start_idx is not None else 0\n        truncated_end = end_idx if end_idx is not None else original_length\n        \n        # Truncate all energy columns\n        for col in energy_cols:\n            if col in row and row[col] is not None:\n                df_truncated.at[idx, col] = row[col][truncated_start:truncated_end]\n        \n        truncated_start_count = truncated_start\n        truncated_end_count = original_length - truncated_end\n        remaining_length = truncated_end - truncated_start\n        \n        truncation_log.append({\n            'prompt_template': row['prompt_template'],\n            'dataset': row['dataset'],\n            'run_id': row['run_id'],\n            'truncated_start_count': truncated_start_count,\n            'truncated_end_count': truncated_end_count,\n            'truncated_total_count': truncated_start_count + truncated_end_count,\n            'original_length': original_length,\n            'remaining_length': remaining_length,\n            'start_truncation_index': start_idx,\n            'end_truncation_index': end_idx,\n            'status': 'Truncated'\n        })\n    \n    truncation_log_df = pd.DataFrame(truncation_log)\n    \n    return df_truncated, truncation_log_df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:27.630212200Z",
     "start_time": "2026-02-26T18:42:27.570613100Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "86ob14a710b",
   "source": "# Apply truncation at both start and end\ndf_truncated, truncation_log = truncate_energy_measurements(df, threshold=75, min_consecutive=20, truncate_end=True)\n\n# Display truncation statistics\nprint(\"Truncation Summary:\")\nprint(truncation_log[['prompt_template', 'run_id', 'truncated_start_count', 'truncated_end_count', \n                       'truncated_total_count', 'original_length', 'remaining_length', 'status']])",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:28.193675600Z",
     "start_time": "2026-02-26T18:42:28.117121300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncation Summary:\n",
      "         prompt_template run_id  truncated_start_count  truncated_end_count  \\\n",
      "0    answer_only_no_expl     r1                     46                    2   \n",
      "1    answer_only_no_expl     r2                     48                    2   \n",
      "2    answer_only_no_expl     r3                     46                    2   \n",
      "3   baseline_single_shot     r1                     48                    2   \n",
      "4   baseline_single_shot     r2                     81                    3   \n",
      "5   baseline_single_shot     r3                     46                    4   \n",
      "6     polite_single_shot     r1                     48                    3   \n",
      "7     polite_single_shot     r2                     46                    2   \n",
      "8     polite_single_shot     r3                     81                    3   \n",
      "9     think_step_by_step     r1                     46                    3   \n",
      "10    think_step_by_step     r2                     48                    0   \n",
      "11    think_step_by_step     r3                     46                    3   \n",
      "\n",
      "    truncated_total_count  original_length  remaining_length     status  \n",
      "0                      48            13272             13224  Truncated  \n",
      "1                      50            13352             13302  Truncated  \n",
      "2                      48            13283             13235  Truncated  \n",
      "3                      50            13336             13286  Truncated  \n",
      "4                      84            13372             13288  Truncated  \n",
      "5                      50            13257             13207  Truncated  \n",
      "6                      51            13277             13226  Truncated  \n",
      "7                      48            13284             13236  Truncated  \n",
      "8                      84            13339             13255  Truncated  \n",
      "9                      49            13284             13235  Truncated  \n",
      "10                     48             1556              1508  Truncated  \n",
      "11                     49            13247             13198  Truncated  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "ih8rjfyyqqg",
   "source": [
    "# Verify truncation worked at both ends\n",
    "row_idx = 4\n",
    "print(f\"Run: {df.iloc[row_idx]['prompt_template']} - {df.iloc[row_idx]['run_id']}\")\n",
    "print(f\"Before truncation - energy_GPU0_USAGE length: {len(df.iloc[row_idx]['energy_GPU0_USAGE'])}\")\n",
    "print(f\"After truncation - energy_GPU0_USAGE length: {len(df_truncated.iloc[row_idx]['energy_GPU0_USAGE'])}\")\n",
    "\n",
    "print(\"\\n\\nGPU usage before truncation (first 100 values):\")\n",
    "print(df.iloc[row_idx]['energy_GPU0_USAGE'][:100])\n",
    "\n",
    "print(\"\\n\\nGPU usage after truncation (first 100 values):\")\n",
    "print(df_truncated.iloc[row_idx]['energy_GPU0_USAGE'][:100])\n",
    "\n",
    "print(\"\\n\\nGPU usage before truncation (last 100 values):\")\n",
    "print(df.iloc[row_idx]['energy_GPU0_USAGE'][-100:])\n",
    "\n",
    "print(\"\\n\\nGPU usage after truncation (last 100 values):\")\n",
    "print(df_truncated.iloc[row_idx]['energy_GPU0_USAGE'][-100:])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:28.804965600Z",
     "start_time": "2026-02-26T18:42:28.784463800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: baseline_single_shot - r2\n",
      "Before truncation - energy_GPU0_USAGE length: 13372\n",
      "After truncation - energy_GPU0_USAGE length: 13288\n",
      "\n",
      "\n",
      "GPU usage before truncation (first 100 values):\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  9  9  9 29 29 35 35 35  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 24 24 24 90 90 88 88 88 91 91 90 90 90 91 91 89 89 89\n",
      " 88 88 89 89]\n",
      "\n",
      "\n",
      "GPU usage after truncation (first 100 values):\n",
      "[90 90 88 88 88 91 91 90 90 90 91 91 89 89 89 88 88 89 89 89 88 88 90 90\n",
      " 90 92 92 91 91 91 89 89 89 89 89 89 89 90 90 90 89 89 89 89 89 90 90 91\n",
      " 91 91 90 90 90 90 90 90 90 92 92 92 91 91 91 91 91 92 92 92 92 92 92 92\n",
      " 92 92 92 93 93 92 92 92 87 87 89 89 89 90 90 90 90 90 91 91 90 90 90 91\n",
      " 91 91 91 91]\n",
      "\n",
      "\n",
      "GPU usage before truncation (last 100 values):\n",
      "[92 92 91 91 91 92 92 92 92 92 92 92 92 92 92 92 92 90 90 90 90 90 90 90\n",
      " 90 91 91 90 90 90 91 91 90 90 90 90 90 90 90 90 90 90 90 90 89 89 89 89\n",
      " 89 89 89 89 90 90 90 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 92 92 92 91 91 91 91 91 91 91 91 91 91 91 91 90 90 90 92 92 92 92\n",
      " 92  0  0  1]\n",
      "\n",
      "\n",
      "GPU usage after truncation (last 100 values):\n",
      "[92 92 92 92 92 91 91 91 92 92 92 92 92 92 92 92 92 92 92 92 90 90 90 90\n",
      " 90 90 90 90 91 91 90 90 90 91 91 90 90 90 90 90 90 90 90 90 90 90 90 89\n",
      " 89 89 89 89 89 89 89 90 90 90 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 91 91 91 92 92 92 91 91 91 91 91 91 91 91 91 91 91 91 90 90 90 92\n",
      " 92 92 92 92]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompt Processing",
   "id": "c14936e27c6f51ea"
  },
  {
   "cell_type": "code",
   "id": "d63uola6hiv",
   "source": "from transformers import AutoTokenizer\n\n# Load the tokenizer\nprint(\"Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder2-3b\")\nprint(\"Tokenizer loaded successfully!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:29.708987700Z",
     "start_time": "2026-02-26T18:42:28.850266600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "vvagrbf0jga",
   "source": "def allocate_measurements_by_tokens(df_truncated, tokenizer):\n    \"\"\"\n    Allocate energy measurements to generations proportionally based on token counts.\n    \n    Args:\n        df_truncated: DataFrame with truncated energy measurements\n        tokenizer: Tokenizer to count tokens\n    \n    Returns:\n        DataFrame with additional columns containing segmented energy data\n    \"\"\"\n    df_segmented = df_truncated.copy()\n    \n    # Get all energy column names\n    energy_cols = [col for col in df_truncated.columns if col.startswith('energy_')]\n    \n    # Initialize new columns\n    df_segmented['cycle_count'] = 0\n    df_segmented['cycle_boundaries'] = None\n    df_segmented['token_counts'] = None\n    \n    for idx, row in df_segmented.iterrows():\n        # Check if required columns exist\n        if 'results_prompt' not in row or 'results_raw_response' not in row:\n            df_segmented.at[idx, 'cycle_count'] = 0\n            df_segmented.at[idx, 'cycle_boundaries'] = []\n            df_segmented.at[idx, 'token_counts'] = []\n            continue\n        \n        prompts = row['results_prompt']\n        raw_responses = row['results_raw_response']\n        \n        if prompts is None or raw_responses is None:\n            df_segmented.at[idx, 'cycle_count'] = 0\n            df_segmented.at[idx, 'cycle_boundaries'] = []\n            df_segmented.at[idx, 'token_counts'] = []\n            continue\n        \n        # Calculate token counts for each generation\n        token_counts = []\n        for prompt, response in zip(prompts, raw_responses):\n            # Remove prompt prefix from response\n            if response.startswith(prompt):\n                generated_text = response[len(prompt):]\n            else:\n                generated_text = response\n            \n            # Count tokens in generated text\n            tokens = tokenizer.encode(generated_text, add_special_tokens=False)\n            token_counts.append(len(tokens))\n        \n        # Calculate total tokens and measurements\n        total_tokens = sum(token_counts)\n        \n        # Get total number of measurements from first energy column\n        total_measurements = len(row[energy_cols[0]]) if energy_cols else 0\n        \n        if total_tokens == 0 or total_measurements == 0:\n            df_segmented.at[idx, 'cycle_count'] = 0\n            df_segmented.at[idx, 'cycle_boundaries'] = []\n            df_segmented.at[idx, 'token_counts'] = []\n            continue\n        \n        # Calculate measurements per token\n        measurements_per_token = total_measurements / total_tokens\n        \n        # Allocate measurements proportionally to each generation\n        cycle_boundaries = []\n        current_idx = 0\n        \n        for i, token_count in enumerate(token_counts):\n            # Calculate number of measurements for this generation\n            if i < len(token_counts) - 1:\n                # For all but last, round to nearest integer\n                n_measurements = round(token_count * measurements_per_token)\n            else:\n                # For last generation, use remaining measurements to ensure exact allocation\n                n_measurements = total_measurements - current_idx\n            \n            end_idx = current_idx + n_measurements\n            cycle_boundaries.append((current_idx, end_idx))\n            current_idx = end_idx\n        \n        # Store results - use loc instead of at to avoid the array issue\n        df_segmented.loc[idx, 'cycle_count'] = len(cycle_boundaries)\n        df_segmented.at[idx, 'cycle_boundaries'] = cycle_boundaries\n        df_segmented.at[idx, 'token_counts'] = token_counts\n        \n        # Segment each energy column by cycles\n        for col in energy_cols:\n            if col in row and row[col] is not None:\n                energy_data = row[col]\n                segmented_data = [energy_data[start:end] for start, end in cycle_boundaries]\n                # Create new column name for cycles\n                cycle_col = f'{col}_cycles'\n                if cycle_col not in df_segmented.columns:\n                    df_segmented[cycle_col] = None\n                df_segmented.at[idx, cycle_col] = segmented_data\n    \n    return df_segmented",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:30.285882400Z",
     "start_time": "2026-02-26T18:42:30.253287600Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "0zlxz1g9k7m",
   "source": "# Apply token-based segmentation\nprint(\"Allocating measurements based on token counts...\")\ndf_segmented = allocate_measurements_by_tokens(df_truncated, tokenizer)\n\n# Display segmentation summary\nprint(\"\\nSegmentation Summary (Token-based):\")\nprint(df_segmented[['prompt_template', 'run_id', 'cycle_count']])\n\n# Show detailed info for one run\nrow_idx = 4\nprint(f\"\\n\\nDetailed info for run: {df_segmented.iloc[row_idx]['prompt_template']} - {df_segmented.iloc[row_idx]['run_id']}\")\nprint(f\"Number of tasks: {len(df_segmented.iloc[row_idx]['results_task_id'])}\")\nprint(f\"Number of cycles: {df_segmented.iloc[row_idx]['cycle_count']}\")\nprint(f\"Total measurements: {len(df_truncated.iloc[row_idx]['energy_Delta'])}\")\nprint(f\"Total tokens generated: {sum(df_segmented.iloc[row_idx]['token_counts'])}\")\nprint(f\"Measurements per token: {len(df_truncated.iloc[row_idx]['energy_Delta']) / sum(df_segmented.iloc[row_idx]['token_counts']):.2f}\")\n\nprint(f\"\\n\\nFirst 10 tasks - Token counts and measurement allocation:\")\nfor i in range(min(10, len(df_segmented.iloc[row_idx]['token_counts']))):\n    start, end = df_segmented.iloc[row_idx]['cycle_boundaries'][i]\n    n_measurements = end - start\n    n_tokens = df_segmented.iloc[row_idx]['token_counts'][i]\n    print(f\"  Task {i}: {n_tokens:4d} tokens -> {n_measurements:4d} measurements (indices [{start:5d}, {end:5d}))\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:31.441165Z",
     "start_time": "2026-02-26T18:42:30.293071300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocating measurements based on token counts...\n",
      "\n",
      "Segmentation Summary (Token-based):\n",
      "         prompt_template run_id  cycle_count\n",
      "0    answer_only_no_expl     r1          164\n",
      "1    answer_only_no_expl     r2          164\n",
      "2    answer_only_no_expl     r3          164\n",
      "3   baseline_single_shot     r1          164\n",
      "4   baseline_single_shot     r2          164\n",
      "5   baseline_single_shot     r3          164\n",
      "6     polite_single_shot     r1          164\n",
      "7     polite_single_shot     r2          164\n",
      "8     polite_single_shot     r3          164\n",
      "9     think_step_by_step     r1          164\n",
      "10    think_step_by_step     r2          164\n",
      "11    think_step_by_step     r3          164\n",
      "\n",
      "\n",
      "Detailed info for run: baseline_single_shot - r2\n",
      "Number of tasks: 164\n",
      "Number of cycles: 164\n",
      "Total measurements: 13288\n",
      "Total tokens generated: 86764\n",
      "Measurements per token: 0.15\n",
      "\n",
      "\n",
      "First 10 tasks - Token counts and measurement allocation:\n",
      "  Task 0:  512 tokens ->   78 measurements (indices [    0,    78))\n",
      "  Task 1:  512 tokens ->   78 measurements (indices [   78,   156))\n",
      "  Task 2:  512 tokens ->   78 measurements (indices [  156,   234))\n",
      "  Task 3:  514 tokens ->   79 measurements (indices [  234,   313))\n",
      "  Task 4:  516 tokens ->   79 measurements (indices [  313,   392))\n",
      "  Task 5:  512 tokens ->   78 measurements (indices [  392,   470))\n",
      "  Task 6:  509 tokens ->   78 measurements (indices [  470,   548))\n",
      "  Task 7:  512 tokens ->   78 measurements (indices [  548,   626))\n",
      "  Task 8:  512 tokens ->   78 measurements (indices [  626,   704))\n",
      "  Task 9:  512 tokens ->   78 measurements (indices [  704,   782))\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# finding relevant sections",
   "id": "b778ef4b0303b8bd"
  },
  {
   "cell_type": "code",
   "id": "ba7s33c5dou",
   "source": "import re\n\ndef extract_valuable_response(response: str, prompt: str) -> str:\n    \"\"\"\n    Extract the valuable portion of the response, truncating after the last meaningful content.\n    \n    Args:\n        response: Raw model response\n        prompt: The prompt that was sent to the model\n    \n    Returns:\n        Truncated response containing only valuable content\n    \"\"\"\n    # Remove the original prompt if it appears at the start\n    if response.startswith(prompt):\n        response = response[len(prompt):]\n    \n    # Strategy 1: Extract markdown code blocks\n    code_block_pattern = r\"```(?:python)?\\s*\\n?(.*?)```\"\n    matches = re.findall(code_block_pattern, response, re.DOTALL)\n    if matches:\n        # Find the position of the last code block\n        last_match_end = response.rfind(\"```\")\n        if last_match_end != -1:\n            # Find the closing ``` \n            return response[:last_match_end + 3]\n    \n    # Strategy 2: Find function/class definitions\n    # Look for the last function or class definition\n    func_class_pattern = r\"(def\\s+\\w+|class\\s+\\w+)\"\n    all_matches = list(re.finditer(func_class_pattern, response))\n    \n    if all_matches:\n        # Find the last function/class definition\n        last_def_start = all_matches[-1].start()\n        \n        # Try to find the end of this definition\n        # Look for: empty lines, next def/class, or common stop markers\n        truncate_pos = len(response)\n        \n        # Check for patterns that indicate end of code\n        remaining = response[last_def_start:]\n        \n        # Find next def/class after some content\n        next_def = re.search(r'\\n(def\\s+\\w+|class\\s+\\w+)', remaining[50:])\n        if next_def:\n            truncate_pos = last_def_start + 50 + next_def.start()\n        \n        # Look for common stop sequences\n        stop_patterns = [\n            r'\\n\\n\\n+',  # Multiple blank lines\n            r'\\nif __name__',  # Main block\n            r'\\n#\\s*test',  # Test comments (case insensitive)\n            r'\\n#\\s*example',  # Example comments\n            r'\\nprint\\(',  # Print statements (often tests)\n        ]\n        \n        for pattern in stop_patterns:\n            match = re.search(pattern, remaining, re.IGNORECASE)\n            if match and match.start() > 20:  # Only if we have some content\n                truncate_pos = min(truncate_pos, last_def_start + match.start())\n        \n        return response[:truncate_pos].rstrip()\n    \n    # Strategy 3: If no clear code structure, look for natural end points\n    # Remove trailing test/example code\n    stop_sequences = [\n        (r'\\n\\n\\n+', 0),  # Multiple blank lines\n        (r'\\nif __name__', 0),\n        (r'\\n#.*test', 0),\n        (r'\\n#.*example', 0),\n        (r'\\nprint\\(', 0),\n        (r'\\nassert\\s', 0),  # Assertions\n    ]\n    \n    result = response\n    for pattern, offset in stop_sequences:\n        match = re.search(pattern, result, re.IGNORECASE)\n        if match and match.start() > 50:  # Ensure we have some content\n            result = result[:match.start() + offset]\n            break\n    \n    return result.rstrip()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T18:42:31.983081400Z",
     "start_time": "2026-02-26T18:42:31.967671600Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
